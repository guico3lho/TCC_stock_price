{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Packages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T15:00:49.250354800Z",
     "start_time": "2023-05-23T15:00:48.701020200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Classes and Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T15:00:49.263249200Z",
     "start_time": "2023-05-23T15:00:49.244358500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dependencies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "train = pd.read_csv('../../assets/data/splits/train/preprocessed.csv')\n",
    "val = pd.read_csv('../../assets/data/splits/val/preprocessed.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T15:00:49.292231400Z",
     "start_time": "2023-05-23T15:00:49.259250700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T15:00:49.306302Z",
     "start_time": "2023-05-23T15:00:49.292231400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "y_train = train['label']\n",
    "y_val = val['label']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T15:00:49.327979200Z",
     "start_time": "2023-05-23T15:00:49.307302500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "with open('../../assets/traditional_assets/cv_vec.pkl', 'rb') as fout:\n",
    "    cv_vec = pickle.load(fout)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T15:00:50.290800600Z",
     "start_time": "2023-05-23T15:00:49.321982600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "with open('../../assets/traditional_assets/tfidf_vec.pkl', 'rb') as fout:\n",
    "    tfidf_vec = pickle.load(fout)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T15:00:50.304787800Z",
     "start_time": "2023-05-23T15:00:50.290800600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['abaixo', 'abertura', 'abicom', 'absurdo', 'aceita', 'acelerar',\n       'acendem', 'acionistas', 'acompanha', 'acordo', 'acucar',\n       'acumula', 'adesao', 'administracao', 'administrativo', 'aereas',\n       'afasta', 'afirma', 'aflicao', 'afunda', 'agenda', 'agitam',\n       'agosto', 'ajudado', 'ajusta', 'ajuste', 'ajustes', 'albacora',\n       'alcanca', 'alerta', 'aliviam', 'aliviar', 'alivio', 'altera',\n       'alteracoes', 'amazonas', 'ambiente', 'ameaca', 'america',\n       'americanas', 'amplia', 'ampliar', 'analise', 'analistas',\n       'antecipa', 'anulacao', 'anulou', 'anuncia', 'anunciar', 'anuncio',\n       'apenas', 'apesar', 'apoiado', 'aponta', 'aposta', 'apostar',\n       'apostas', 'apreensao', 'aprova', 'aprovacao', 'aprovam',\n       'aprovar', 'aproveitar', 'aproxima', 'aquisicao', 'aquisicoes',\n       'araucaria', 'arbitragem', 'arezzo', 'argentina', 'arrecada',\n       'arrefecimento', 'arrendamento', 'arrendar', 'assembleia',\n       'assina', 'assinam', 'assume', 'assumir', 'ataque', 'atencao',\n       'atender', 'atento', 'atenua', 'atinge', 'atingir', 'ativos',\n       'audiencia', 'aumenta', 'aumentam', 'aumentar', 'aumento',\n       'aumentos', 'autonomia', 'autoriza', 'auxilio', 'avalia', 'avanca',\n       'avanco', 'aversao', 'aviacao', 'baixar', 'baixas', 'balanco',\n       'balancos', 'bancos', 'barata', 'barato', 'barbosa', 'barril',\n       'barris', 'baseada', 'bateria', 'bidi11', 'bilhao', 'bilhoes',\n       'biodiesel', 'blocos', 'bloqueiam', 'bolivia', 'bolsas',\n       'bolsonaro', 'botijao', 'bovespa', 'bradesco', 'branco', 'brasil',\n       'brasileiras', 'brasilia', 'braskem', 'bsbios', 'buscar', 'buzios',\n       'caindo', 'camara', 'cambial', 'cambio', 'caminha', 'caminho',\n       'caminhoneiros', 'campos', 'capacidade', 'carbono', 'carona',\n       'carrefour', 'carteira', 'carteiras', 'castello', 'cautela',\n       'cenario', 'centromenos', 'cessao', 'chamam', 'chances',\n       'clientes', 'climatica', 'coisas', 'coletiva', 'coloca',\n       'colombia', 'comando', 'combate', 'combustiveis', 'combustivel',\n       'comeca', 'comeco', 'comissao', 'comite', 'commodities',\n       'companhia', 'compass', 'compensacoes', 'competitividade',\n       'compra', 'comprar', 'compras', 'compre', 'concessao',\n       'concessoes', 'conclui', 'concorrencia', 'concorrentes',\n       'condenacoes', 'confira', 'confirma', 'conforme', 'congresso',\n       'conselheiros', 'conselho', 'consorcio', 'construcao', 'consumo',\n       'conter', 'contra', 'contramao', 'contrata', 'contratacao',\n       'contrato', 'contratos', 'controle', 'copagaz', 'coparticipacao',\n       'coronavirus', 'corporativa', 'corporativas', 'corporativo',\n       'corretoras', 'cortar', 'cotado', 'covidmenos', 'cozinha',\n       'credit', 'credito', 'cresce', 'crescem', 'crescer', 'criterios',\n       'critica', 'cumpre', 'cyrela', 'daniel', 'debate', 'decepcao',\n       'decisao', 'decisoes', 'declaracoes', 'declinio', 'defasada',\n       'defasagem', 'defende', 'define', 'deixar', 'demanda', 'denuncia',\n       'deputados', 'derivados', 'derrocada', 'derruba', 'derrubam',\n       'desaba', 'desabam', 'desativar', 'desclassifica', 'descola',\n       'desconforto', 'desconto', 'descontos', 'descubra', 'desempenho',\n       'desinvestimentos', 'desiste', 'despenca', 'destacam', 'destaque',\n       'destaques', 'destoa', 'devera', 'dezembro', 'diante', 'diesel',\n       'dificil', 'dinheiro', 'direcao', 'direito', 'direto', 'diretor',\n       'diretoria', 'discreta', 'discurso', 'discute', 'dispara',\n       'disparada', 'disparam', 'disparar', 'disputa', 'distribuidora',\n       'distribuidoras', 'distribuir', 'divida', 'dividas', 'dividendo',\n       'dividendos', 'divulga', 'domestico', 'duvidas', 'economia',\n       'economica', 'ecorodovias', 'edital', 'efeitos', 'eficiente',\n       'eleger', 'eleicao', 'eleicoes', 'eletrobras', 'elevam', 'elevar',\n       'embraer', 'emergencial', 'emergentes', 'emissao', 'emissoes',\n       'emprego', 'empresa', 'empresas', 'encerra', 'encerrar',\n       'endossada', 'energia', 'energy', 'enfrentar', 'engata',\n       'enquanto', 'ensaia', 'entenda', 'entrada', 'entram', 'entrar',\n       'entrou', 'equinor', 'equipe', 'escala', 'esclarecer', 'escolhe',\n       'espaco', 'espera', 'esperado', 'espere', 'espirito',\n       'estabilidade', 'estabilizacao', 'estados', 'estatais', 'estatal',\n       'estavel', 'estimativa', 'estimulos', 'estoques', 'estradas',\n       'estrategico', 'estreia', 'estreiam', 'estuda', 'etanol', 'europa',\n       'evento', 'exagerada', 'excelerate', 'executivo', 'executivos',\n       'exmenos', 'expectativa', 'expectativas', 'exportacao',\n       'exportacoes', 'exportadoras', 'exterior', 'externo', 'extracao',\n       'fabrica', 'fabricas', 'fachin', 'familias', 'favoravel',\n       'favorita', 'favoritas', 'fechamento', 'fechar', 'federal',\n       'felipe', 'feriado', 'feriados', 'ferreira', 'fertilizantes',\n       'fevereiro', 'financiar', 'fiscais', 'fiscal', 'flerta', 'fluxys',\n       'folego', 'follow', 'fontes', 'fornecimento', 'fortes', 'fracas',\n       'fraqueza', 'fundos', 'fusoes', 'futura', 'futuro', 'ganham',\n       'ganhar', 'ganhos', 'garante', 'gasoduto', 'gasodutos', 'gasolina',\n       'gaspetro', 'gastos', 'gerdau', 'gerencia', 'gerente', 'gestao',\n       'globais', 'global', 'goldman', 'governanca', 'governo', 'grafica',\n       'guedes', 'guiado', 'hapvida', 'havera', 'hering', 'hesita',\n       'hidratado', 'hidrica', 'historia', 'historica', 'historico',\n       'holanda', 'holofotes', 'hypera', 'ibovespa', 'impacto',\n       'importacao', 'importadores', 'importar', 'impostos', 'impulso',\n       'inadmissivel', 'inaugura', 'incerteza', 'incertezas', 'inclui',\n       'indefinicao', 'indica', 'indicacao', 'indicacoes', 'indicada',\n       'indicadas', 'indicam', 'indice', 'industria', 'inedito',\n       'inflacao', 'influencia', 'informa', 'ingerencia', 'inicia',\n       'inicio', 'insider', 'institucional', 'instituicoes',\n       'interessados', 'interesse', 'interferencia', 'internacionais',\n       'internacional', 'interno', 'intervencao', 'inverte', 'investidor',\n       'investidores', 'investigacao', 'investigar', 'investimentos',\n       'investir', 'investira', 'ipcamenos', 'ipiranga',\n       'irregularidades', 'itausa', 'janeiro', 'jornal', 'julgamento',\n       'justica', 'karoon', 'klabin', 'latina', 'lavagem', 'leilao',\n       'leiloes', 'leniencia', 'lentidao', 'levantamento', 'levantar',\n       'lewandowski', 'libera', 'liberal', 'licitacao', 'lidera',\n       'lideram', 'liderando', 'ligadas', 'liminar', 'limitam', 'linhas',\n       'liquidez', 'liquigas', 'locais', 'localiza', 'lucrar', 'lucros',\n       'magalu', 'magazine', 'maiores', 'mandados', 'manifesta',\n       'manifestacoes', 'mantem', 'manter', 'manterao', 'manutencao',\n       'maquina', 'marcada', 'marfrig', 'marlim', 'martins', 'maxima',\n       'maximas', 'medidas', 'melhor', 'melhora', 'melhores', 'meliuz',\n       'mensal', 'mercado', 'mercados', 'mesmos', 'metade', 'mexico',\n       'milhao', 'milhas', 'milhoes', 'mineracao', 'minerio', 'minerva',\n       'minima', 'minimas', 'minimo', 'ministerio', 'ministro',\n       'minoritarios', 'miranda', 'mistura', 'momento', 'monopolio',\n       'montezano', 'moodys', 'morgan', 'mostra', 'motivo', 'motivos',\n       'mourao', 'movida', 'movimento', 'mubadala', 'mudanca', 'mudancas',\n       'nacional', 'naomenos', 'natura', 'natural', 'necton', 'negativa',\n       'negativo', 'negociacao', 'negociacoes', 'negocios', 'neoenergia',\n       'ninguem', 'nitrogenados', 'niveis', 'noticiario', 'noticias',\n       'novembro', 'novidades', 'oceanpact', 'odebrecht', 'oferta',\n       'ofertas', 'office', 'offshore', 'ofusca', 'omicron', 'onerosa',\n       'opcoes', 'operacao', 'operador', 'operar', 'oportunidades',\n       'orcamento', 'oscila', 'otimismo', 'outras', 'outubro', 'pacote',\n       'pactual', 'pagamento', 'pagara', 'pagarao', 'pandemia', 'papeis',\n       'parada', 'parana', 'parceria', 'parcial', 'parecer', 'paridade',\n       'participacao', 'partilha', 'partir', 'patamar', 'patinho',\n       'percepcao', 'perdas', 'perfura', 'permanece', 'permanente',\n       'permite', 'perspectiva', 'pessimismo', 'pessoas', 'petrobras',\n       'petroleira', 'petroleiros', 'petroleo', 'petroleum',\n       'petroreconcavo', 'petrorio', 'petros', 'piorar', 'planeja',\n       'planos', 'plataforma', 'plataformas', 'plenario', 'pmenos',\n       'podera', 'policia', 'politica', 'politico', 'politicomenos',\n       'pontos', 'portfolio', 'positiva', 'positivo', 'possibilidade',\n       'possivel', 'postos', 'potencial', 'potiguar', 'powell',\n       'precatorios', 'precisa', 'precomenos', 'precos', 'preferidas',\n       'pregao', 'prejuizo', 'premenos', 'preocupa', 'preocupacao',\n       'preocupacoes', 'presidente', 'pressao', 'pressiona',\n       'pressionado', 'pressoes', 'pretende', 'prevalece', 'previa',\n       'primeira', 'principais', 'privada', 'privatizacao', 'privatizada',\n       'privatizar', 'processamento', 'processo', 'producao', 'profundo',\n       'programa', 'programada', 'projecoes', 'projeto', 'promessa',\n       'promete', 'proposta', 'propostas', 'prorroga', 'protesto',\n       'protestos', 'proxima', 'proximo', 'proximos', 'publica', 'puxada',\n       'puxado', 'qualicorp', 'quarta', 'quatro', 'quebra', 'quedas',\n       'questiona', 'quinta', 'raizen', 'randon', 'ranking', 'rating',\n       'reafirma', 'reajusta', 'reajuste', 'reajustes', 'realiza',\n       'realizacao', 'recebe', 'receio', 'receios', 'recomendacao',\n       'recomendacoes', 'recomendada', 'recomendadas', 'recomendam',\n       'recompra', 'recorde', 'recordes', 'recupera', 'recuperacao',\n       'recursos', 'reducao', 'reduzido', 'reduzir', 'reduzira',\n       'refinaria', 'refinarias', 'refino', 'reforca', 'reforma',\n       'regiao', 'registra', 'reitera', 'relator', 'remuneracao',\n       'render', 'rendeu', 'renegociam', 'renner', 'renova', 'renovar',\n       'renovavel', 'repasse', 'represamento', 'reserve', 'resiliencia',\n       'resiste', 'respaldo', 'respeito', 'respiro', 'restricoes',\n       'resultado', 'resultados', 'retoma', 'retomada', 'retorno',\n       'retornos', 'reverte', 'reverter', 'riscos', 'roberto', 'robusto',\n       'rodada', 'royalties', 'saltam', 'samsung', 'santander', 'santos',\n       'satisfaz', 'secretario', 'seguida', 'seguidas', 'seguido',\n       'seguindo', 'seguir', 'segunda', 'segundo', 'selecao', 'seleciona',\n       'semana', 'semanais', 'semanal', 'semanas', 'senado', 'senador',\n       'sentenca', 'sequencia', 'sergio', 'sergipe', 'servico',\n       'servicos', 'sessao', 'setembro', 'setores', 'siderurgia',\n       'siderurgicas', 'simples', 'sinais', 'sinaliza', 'sindicato',\n       'sinqia', 'sismica', 'situacao', 'smartfit', 'smenos', 'smiles',\n       'startups', 'street', 'subindo', 'subira', 'subsidiar',\n       'subsidiaria', 'subsidiarias', 'substitui', 'sugerem', 'sugeridas',\n       'sugestoes', 'suisse', 'supera', 'superar', 'surpreendente',\n       'suspende', 'suspensao', 'sustenta', 'suzano', 'taxacao', 'teaser',\n       'tecnologia', 'tendencia', 'tensao', 'terceiro', 'termeletricas',\n       'termica', 'termicas', 'terminal', 'terreno', 'terrestres',\n       'ticket', 'tirados', 'titulo', 'titulos', 'tornamenos',\n       'totalenergies', 'trabalhista', 'trabalho', 'transporte',\n       'treasuries', 'tregua', 'tributaria', 'trimestral', 'trimestre',\n       'trocar', 'trocas', 'ultima', 'ultrapar', 'ultrapassa', 'unibanco',\n       'unidade', 'unidades', 'unidas', 'unigel', 'usiminas', 'usinas',\n       'vacina', 'valecard', 'valemenos', 'valores', 'varejistas',\n       'varejo', 'variante', 'vencimento', 'vencimentos', 'vendas',\n       'vender', 'vermelho', 'vespera', 'vinculante', 'vinculantes',\n       'volatil', 'volatilidade', 'volume', 'vontade', 'warren'],\n      dtype=object)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_vec.get_feature_names_out()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T15:00:50.337770100Z",
     "start_time": "2023-05-23T15:00:50.305788Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Grid Params"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### KNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_params = {\n",
    "    # 'n_neighbors': [11, 21, 40, 60, 80, 100],\n",
    "    'n_neighbors': [15 ,17 ,19, 21, 23, 25, 27],\n",
    "    'metric': ['cosine'],\n",
    "    'weights': ['distance']\n",
    "    # 'weights': ['uniform', 'distance'],\n",
    "    # 'metric': ['cosine']\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T15:00:50.707664500Z",
     "start_time": "2023-05-23T15:00:50.340768200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SVM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_params = {\n",
    "    # 'C': [1,10, 50, 100],\n",
    "    'C': [1,5,10],\n",
    "    # 'C': [1,5,10],\n",
    "    # 'kernel': ['rbf']\n",
    "    # 'kernel' : ['rbf'],\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T15:00:50.708666600Z",
     "start_time": "2023-05-23T15:00:50.695672300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Naive Bayes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb_params = {\n",
    "    'alpha': [0.1, 1, 10],\n",
    "    'fit_prior': [True, False]\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T15:00:50.727673300Z",
     "start_time": "2023-05-23T15:00:50.697671500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_params = {\n",
    "    'penalty': ['l1','l2', None],\n",
    "    'C': [0.1, 1, 10],\n",
    "    'solver': ['liblinear','sag', 'saga']\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T15:00:50.755656500Z",
     "start_time": "2023-05-23T15:00:50.730671700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tuning and Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "\n",
    "split_index = [-1] * len(train) + [0] * len(val)\n",
    "\n",
    "X = pd.concat([train, val], axis=0, ignore_index=True)\n",
    "\n",
    "y = np.concatenate((y_train, y_val), axis=0)\n",
    "pds = PredefinedSplit(test_fold=split_index)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T15:00:50.767649300Z",
     "start_time": "2023-05-23T15:00:50.744663300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Count Vectorizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "      abaixo  abertura  abicom  absurdo  aceita  acelerar  acendem  \\\n0          0         0       0        0       0         0        0   \n1          0         0       0        0       0         0        0   \n2          0         0       0        0       0         0        0   \n3          0         0       0        0       0         0        0   \n4          0         0       0        0       0         0        0   \n...      ...       ...     ...      ...     ...       ...      ...   \n1828       0         0       0        0       0         0        0   \n1829       0         0       0        0       0         0        0   \n1830       0         0       0        0       0         0        0   \n1831       0         0       0        0       0         0        0   \n1832       0         0       0        0       0         0        0   \n\n      acionistas  acompanha  acordo  ...  vender  vermelho  vespera  \\\n0              0          0       1  ...       0         0        0   \n1              0          0       0  ...       0         0        0   \n2              0          0       0  ...       0         0        0   \n3              0          0       0  ...       1         0        0   \n4              0          0       0  ...       0         0        0   \n...          ...        ...     ...  ...     ...       ...      ...   \n1828           0          0       0  ...       0         0        0   \n1829           0          0       0  ...       0         0        0   \n1830           0          0       0  ...       0         0        0   \n1831           0          0       0  ...       0         0        0   \n1832           0          0       0  ...       0         0        0   \n\n      vinculante  vinculantes  volatil  volatilidade  volume  vontade  warren  \n0              0            0        0             0       0        0       0  \n1              0            0        0             0       0        0       0  \n2              0            0        0             0       0        0       0  \n3              0            0        0             0       0        0       0  \n4              0            0        0             0       0        0       0  \n...          ...          ...      ...           ...     ...      ...     ...  \n1828           0            0        0             0       0        0       0  \n1829           0            0        0             0       0        0       0  \n1830           0            0        0             0       0        0       0  \n1831           0            0        0             0       0        0       0  \n1832           0            0        0             0       0        0       0  \n\n[1833 rows x 894 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>abaixo</th>\n      <th>abertura</th>\n      <th>abicom</th>\n      <th>absurdo</th>\n      <th>aceita</th>\n      <th>acelerar</th>\n      <th>acendem</th>\n      <th>acionistas</th>\n      <th>acompanha</th>\n      <th>acordo</th>\n      <th>...</th>\n      <th>vender</th>\n      <th>vermelho</th>\n      <th>vespera</th>\n      <th>vinculante</th>\n      <th>vinculantes</th>\n      <th>volatil</th>\n      <th>volatilidade</th>\n      <th>volume</th>\n      <th>vontade</th>\n      <th>warren</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1828</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1829</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1830</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1831</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1832</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1833 rows Ã— 894 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cv = cv_vec.transform(X['title']).toarray()\n",
    "pd.DataFrame(X_cv, columns=cv_vec.get_feature_names_out())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T15:00:50.820618600Z",
     "start_time": "2023-05-23T15:00:50.761653Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T15:00:50.836621800Z",
     "start_time": "2023-05-23T15:00:50.821619Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV results for KNeighborsClassifier\n",
      "Best Score of train set: 0.5597221601822486\n",
      "Best estimator: KNeighborsClassifier(metric='cosine', n_neighbors=23, weights='distance')\n",
      "Best parameter set: {'metric': 'cosine', 'n_neighbors': 23, 'weights': 'distance'}\n",
      "Best CV results for SVC\n",
      "Best Score of train set: 0.574468813746073\n",
      "Best estimator: SVC(C=1)\n",
      "Best parameter set: {'C': 1}\n",
      "Best CV results for MultinomialNB\n",
      "Best Score of train set: 0.5739298104554726\n",
      "Best estimator: MultinomialNB(alpha=10)\n",
      "Best parameter set: {'alpha': 10, 'fit_prior': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "30 fits failed out of a total of 135.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1216, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\svm\\_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\svm\\_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='None' and loss='logistic_regression' is not supported, Parameters: penalty=None, loss='logistic_regression', dual=False\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.54828546        nan 0.54828546 0.57339081 0.5755766  0.5755766\n",
      "        nan 0.53465106 0.53192776 0.5553878         nan 0.55538929\n",
      " 0.54445586 0.54445586 0.54500082        nan 0.53301767 0.53301916\n",
      " 0.54610116        nan 0.54119802 0.53793273 0.53793273 0.54229836\n",
      "        nan 0.53465255 0.53029139]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV results for LogisticRegression\n",
      "Best Score of train set: 0.5755765995145993\n",
      "Best estimator: LogisticRegression(C=0.1, solver='sag')\n",
      "Best parameter set: {'C': 0.1, 'penalty': 'l2', 'solver': 'sag'}\n"
     ]
    },
    {
     "data": {
      "text/plain": "             model_name  best_score  \\\n0  KNeighborsClassifier    0.559722   \n1                   SVC    0.574469   \n2         MultinomialNB    0.573930   \n3    LogisticRegression    0.575577   \n\n                                      best_estimator  \\\n0  KNeighborsClassifier(metric='cosine', n_neighb...   \n1                                           SVC(C=1)   \n2                            MultinomialNB(alpha=10)   \n3            LogisticRegression(C=0.1, solver='sag')   \n\n                                         best_params  \n0  {'metric': 'cosine', 'n_neighbors': 23, 'weigh...  \n1                                           {'C': 1}  \n2                   {'alpha': 10, 'fit_prior': True}  \n3       {'C': 0.1, 'penalty': 'l2', 'solver': 'sag'}  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model_name</th>\n      <th>best_score</th>\n      <th>best_estimator</th>\n      <th>best_params</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>KNeighborsClassifier</td>\n      <td>0.559722</td>\n      <td>KNeighborsClassifier(metric='cosine', n_neighb...</td>\n      <td>{'metric': 'cosine', 'n_neighbors': 23, 'weigh...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>SVC</td>\n      <td>0.574469</td>\n      <td>SVC(C=1)</td>\n      <td>{'C': 1}</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>MultinomialNB</td>\n      <td>0.573930</td>\n      <td>MultinomialNB(alpha=10)</td>\n      <td>{'alpha': 10, 'fit_prior': True}</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>LogisticRegression</td>\n      <td>0.575577</td>\n      <td>LogisticRegression(C=0.1, solver='sag')</td>\n      <td>{'C': 0.1, 'penalty': 'l2', 'solver': 'sag'}</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# from hypopt import GridSearch\n",
    "\n",
    "model_params = ([KNeighborsClassifier(), SVC(), MultinomialNB(), LogisticRegression()],\n",
    "                [knn_params, svm_params, nb_params, lr_params])\n",
    "\n",
    "list_best_models_params = []\n",
    "for model, params in zip(model_params[0], model_params[1]):\n",
    "    gs = GridSearchCV(model,\n",
    "                      param_grid=params,\n",
    "                      )\n",
    "\n",
    "    gs.fit(X_cv, y)\n",
    "    print(f\"Best CV results for {model.__class__.__name__}\")\n",
    "    print(\"Best Score of train set: \" + str(gs.best_score_))\n",
    "    print(\"Best estimator: \" + str(gs.best_estimator_))\n",
    "    print(\"Best parameter set: \" + str(gs.best_params_))\n",
    "\n",
    "    store_best_model_configs = {\n",
    "        'model_name': model.__class__.__name__,\n",
    "        'best_score': gs.best_score_,\n",
    "        'best_estimator': gs.best_estimator_,\n",
    "        'best_params': gs.best_params_\n",
    "    }\n",
    "\n",
    "    list_best_models_params.append(store_best_model_configs)\n",
    "\n",
    "df_best_models_params = pd.DataFrame(list_best_models_params)\n",
    "df_best_models_params.to_csv('../../assets/traditional_assets/best_models_params_cv.csv', index=False)\n",
    "\n",
    "df_best_models_params\n",
    "# cv_best_model = gs.best_estimator_\n",
    "# print(\"Test Score: \" + str(gs.score(X_val_cv, y_val)))\n",
    "# print(\"----------------------------------------------------\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T15:04:42.285254400Z",
     "start_time": "2023-05-23T15:00:50.837621800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "LogisticRegression(C=0.1, solver='sag')",
      "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.1, solver=&#x27;sag&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.1, solver=&#x27;sag&#x27;)</pre></div></div></div></div></div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cv_best_model = gs.best_estimator_\n",
    "cv_best_model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T15:04:42.300245500Z",
     "start_time": "2023-05-23T15:04:42.286254Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T15:04:42.344219300Z",
     "start_time": "2023-05-23T15:04:42.301245600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### TF-IDF"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "      abaixo  abertura  abicom  absurdo  aceita  acelerar  acendem  \\\n0        0.0       0.0     0.0      0.0     0.0       0.0      0.0   \n1        0.0       0.0     0.0      0.0     0.0       0.0      0.0   \n2        0.0       0.0     0.0      0.0     0.0       0.0      0.0   \n3        0.0       0.0     0.0      0.0     0.0       0.0      0.0   \n4        0.0       0.0     0.0      0.0     0.0       0.0      0.0   \n...      ...       ...     ...      ...     ...       ...      ...   \n1828     0.0       0.0     0.0      0.0     0.0       0.0      0.0   \n1829     0.0       0.0     0.0      0.0     0.0       0.0      0.0   \n1830     0.0       0.0     0.0      0.0     0.0       0.0      0.0   \n1831     0.0       0.0     0.0      0.0     0.0       0.0      0.0   \n1832     0.0       0.0     0.0      0.0     0.0       0.0      0.0   \n\n      acionistas  acompanha    acordo  ...    vender  vermelho  vespera  \\\n0            0.0        0.0  0.409233  ...  0.000000       0.0      0.0   \n1            0.0        0.0  0.000000  ...  0.000000       0.0      0.0   \n2            0.0        0.0  0.000000  ...  0.000000       0.0      0.0   \n3            0.0        0.0  0.000000  ...  0.442358       0.0      0.0   \n4            0.0        0.0  0.000000  ...  0.000000       0.0      0.0   \n...          ...        ...       ...  ...       ...       ...      ...   \n1828         0.0        0.0  0.000000  ...  0.000000       0.0      0.0   \n1829         0.0        0.0  0.000000  ...  0.000000       0.0      0.0   \n1830         0.0        0.0  0.000000  ...  0.000000       0.0      0.0   \n1831         0.0        0.0  0.000000  ...  0.000000       0.0      0.0   \n1832         0.0        0.0  0.000000  ...  0.000000       0.0      0.0   \n\n      vinculante  vinculantes  volatil  volatilidade  volume  vontade  warren  \n0            0.0          0.0      0.0           0.0     0.0      0.0     0.0  \n1            0.0          0.0      0.0           0.0     0.0      0.0     0.0  \n2            0.0          0.0      0.0           0.0     0.0      0.0     0.0  \n3            0.0          0.0      0.0           0.0     0.0      0.0     0.0  \n4            0.0          0.0      0.0           0.0     0.0      0.0     0.0  \n...          ...          ...      ...           ...     ...      ...     ...  \n1828         0.0          0.0      0.0           0.0     0.0      0.0     0.0  \n1829         0.0          0.0      0.0           0.0     0.0      0.0     0.0  \n1830         0.0          0.0      0.0           0.0     0.0      0.0     0.0  \n1831         0.0          0.0      0.0           0.0     0.0      0.0     0.0  \n1832         0.0          0.0      0.0           0.0     0.0      0.0     0.0  \n\n[1833 rows x 894 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>abaixo</th>\n      <th>abertura</th>\n      <th>abicom</th>\n      <th>absurdo</th>\n      <th>aceita</th>\n      <th>acelerar</th>\n      <th>acendem</th>\n      <th>acionistas</th>\n      <th>acompanha</th>\n      <th>acordo</th>\n      <th>...</th>\n      <th>vender</th>\n      <th>vermelho</th>\n      <th>vespera</th>\n      <th>vinculante</th>\n      <th>vinculantes</th>\n      <th>volatil</th>\n      <th>volatilidade</th>\n      <th>volume</th>\n      <th>vontade</th>\n      <th>warren</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.409233</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.442358</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1828</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1829</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1830</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1831</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1832</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1833 rows Ã— 894 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train_tfidf = tfidf_vec.transform(X_train['title'])\n",
    "# X_val_tfidf = tfidf_vec.transform(X_val['title'])\n",
    "# X_train_tfidf\n",
    "X_tfidf = tfidf_vec.transform(X['title']).toarray()\n",
    "pd.DataFrame(X_tfidf, columns=tfidf_vec.get_feature_names_out())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T15:04:42.477143500Z",
     "start_time": "2023-05-23T15:04:42.317237Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best TF-IDF results for KNeighborsClassifier\n",
      "Best Score on train set: 0.5771950983457661\n",
      "Best estimator: KNeighborsClassifier(metric='cosine', n_neighbors=23, weights='distance')\n",
      "Best parameter set: {'metric': 'cosine', 'n_neighbors': 23, 'weights': 'distance'}\n",
      "\n",
      "Best TF-IDF results for SVC\n",
      "Best Score on train set: 0.5700957400872528\n",
      "Best estimator: SVC(C=1)\n",
      "Best parameter set: {'C': 1}\n",
      "\n",
      "Best TF-IDF results for MultinomialNB\n",
      "Best Score on train set: 0.5597474724914757\n",
      "Best estimator: MultinomialNB(alpha=1)\n",
      "Best parameter set: {'alpha': 1, 'fit_prior': True}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best TF-IDF results for LogisticRegression\n",
      "Best Score on train set: 0.570658566727714\n",
      "Best estimator: LogisticRegression(C=1, penalty='l1', solver='liblinear')\n",
      "Best parameter set: {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "30 fits failed out of a total of 135.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1216, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\svm\\_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\svm\\_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='None' and loss='logistic_regression' is not supported, Parameters: penalty=None, loss='logistic_regression', dual=False\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\guimi\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.55046381        nan 0.55046381 0.55264811 0.55319307 0.55319307\n",
      "        nan 0.53628594 0.54174446 0.57065857        nan 0.57011361\n",
      " 0.55701523 0.55810515 0.55810515        nan 0.53737884 0.54010512\n",
      " 0.54774199        nan 0.54611158 0.5450172  0.5450172  0.5450172\n",
      "        nan 0.53683239 0.54065306]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "             model_name  best_score  \\\n0  KNeighborsClassifier    0.577195   \n1                   SVC    0.570096   \n2         MultinomialNB    0.559747   \n3    LogisticRegression    0.570659   \n\n                                      best_estimator  \\\n0  KNeighborsClassifier(metric='cosine', n_neighb...   \n1                                           SVC(C=1)   \n2                             MultinomialNB(alpha=1)   \n3  LogisticRegression(C=1, penalty='l1', solver='...   \n\n                                         best_params  \n0  {'metric': 'cosine', 'n_neighbors': 23, 'weigh...  \n1                                           {'C': 1}  \n2                    {'alpha': 1, 'fit_prior': True}  \n3   {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model_name</th>\n      <th>best_score</th>\n      <th>best_estimator</th>\n      <th>best_params</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>KNeighborsClassifier</td>\n      <td>0.577195</td>\n      <td>KNeighborsClassifier(metric='cosine', n_neighb...</td>\n      <td>{'metric': 'cosine', 'n_neighbors': 23, 'weigh...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>SVC</td>\n      <td>0.570096</td>\n      <td>SVC(C=1)</td>\n      <td>{'C': 1}</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>MultinomialNB</td>\n      <td>0.559747</td>\n      <td>MultinomialNB(alpha=1)</td>\n      <td>{'alpha': 1, 'fit_prior': True}</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>LogisticRegression</td>\n      <td>0.570659</td>\n      <td>LogisticRegression(C=1, penalty='l1', solver='...</td>\n      <td>{'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model_params = ([KNeighborsClassifier(), SVC(), MultinomialNB(), LogisticRegression()],\n",
    "                [knn_params, svm_params, nb_params, lr_params])\n",
    "\n",
    "list_best_models_params = []\n",
    "for model, params in zip(model_params[0], model_params[1]):\n",
    "    gs = GridSearchCV(model,\n",
    "                      param_grid=params,\n",
    "                      )\n",
    "    gs.fit(X_tfidf, y)\n",
    "    print(f\"Best TF-IDF results for {model.__class__.__name__}\")\n",
    "    print(\"Best Score on train set: \" + str(gs.best_score_))\n",
    "    print(\"Best estimator: \" + str(gs.best_estimator_))\n",
    "    print(\"Best parameter set: \" + str(gs.best_params_) + \"\\n\")\n",
    "    store_best_model_configs = {\n",
    "        'model_name': model.__class__.__name__,\n",
    "        'best_score': gs.best_score_,\n",
    "        'best_estimator': gs.best_estimator_,\n",
    "        'best_params': gs.best_params_\n",
    "    }\n",
    "\n",
    "    list_best_models_params.append(store_best_model_configs)\n",
    "\n",
    "df_best_models_params = pd.DataFrame(list_best_models_params)\n",
    "df_best_models_params.to_csv('../../assets/traditional_assets/best_models_params_tfidf.csv', index=False)\n",
    "df_best_models_params\n",
    "\n",
    "\n",
    "# decide_best_model =\n",
    "# print(\"Test Score: \" + str(gs.score(X_val, y_val)))\n",
    "# print(\"----------------------------------------------------\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T15:08:06.492287800Z",
     "start_time": "2023-05-23T15:04:42.419177400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "LogisticRegression(C=0.1, solver='sag')",
      "text/html": "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.1, solver=&#x27;sag&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.1, solver=&#x27;sag&#x27;)</pre></div></div></div></div></div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cv = cv_vec.transform(train['title']).toarray()\n",
    "# pd.DataFrame(X_cv, columns=cv_vec.get_feature_names_out())\n",
    "cv_best_model = LogisticRegression(C=0.1, solver='sag', penalty='l2').fit(X_cv, train['label'])\n",
    "cv_best_model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T15:08:06.535261900Z",
     "start_time": "2023-05-23T15:08:06.492287800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "KNeighborsClassifier(metric='cosine', n_neighbors=23, weights='distance')",
      "text/html": "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(metric=&#x27;cosine&#x27;, n_neighbors=23, weights=&#x27;distance&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(metric=&#x27;cosine&#x27;, n_neighbors=23, weights=&#x27;distance&#x27;)</pre></div></div></div></div></div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf = tfidf_vec.transform(train['title']).toarray()\n",
    "# pd.DataFrame(X_cv, columns=tfidf.get_feature_names_out())\n",
    "tfidf_best_model = KNeighborsClassifier(metric='cosine', n_neighbors=23, weights='distance').fit(X_tfidf, train['label'])\n",
    "tfidf_best_model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T15:08:06.582234400Z",
     "start_time": "2023-05-23T15:08:06.508278400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Outputs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "with open('../../assets/traditional_assets/cv_set.pkl', 'wb') as fout:\n",
    "    pickle.dump((cv_vec, cv_best_model), fout)\n",
    "\n",
    "with open('../../assets/traditional_assets/tfidf_set.pkl', 'wb') as fout:\n",
    "    pickle.dump((tfidf_vec, tfidf_best_model), fout)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T15:08:06.600224900Z",
     "start_time": "2023-05-23T15:08:06.524268900Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
