{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Packages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T15:00:49.250354800Z",
     "start_time": "2023-05-23T15:00:48.701020200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Classes and Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T15:00:49.263249200Z",
     "start_time": "2023-05-23T15:00:49.244358500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dependencies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "train = pd.read_csv('../../assets/data/splits/train/preprocessed.csv')\n",
    "val = pd.read_csv('../../assets/data/splits/val/preprocessed.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T15:00:49.292231400Z",
     "start_time": "2023-05-23T15:00:49.259250700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T15:00:49.306302Z",
     "start_time": "2023-05-23T15:00:49.292231400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "y_train = train['label']\n",
    "y_val = val['label']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T15:00:49.327979200Z",
     "start_time": "2023-05-23T15:00:49.307302500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "with open('../../assets/traditional_assets/cv_vec.pkl', 'rb') as fout:\n",
    "    cv_vec = pickle.load(fout)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T15:00:50.290800600Z",
     "start_time": "2023-05-23T15:00:49.321982600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "with open('../../assets/traditional_assets/tfidf_vec.pkl', 'rb') as fout:\n",
    "    tfidf_vec = pickle.load(fout)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T15:00:50.304787800Z",
     "start_time": "2023-05-23T15:00:50.290800600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['abaixo', 'abertura', 'abicom', 'absurdo', 'aceita', 'acelera',\n       'acelerar', 'acionistas', 'acompanha', 'acordo', 'acucar',\n       'acumula', 'administrativo', 'aereas', 'afirma', 'aflicao',\n       'afunda', 'agencia', 'agenda', 'agitam', 'agosto', 'ajudar',\n       'ajusta', 'ajustar', 'ajuste', 'ajustes', 'alagoas', 'albacora',\n       'alcanca', 'alerta', 'alertam', 'aliviar', 'alivio', 'altera',\n       'alteracoes', 'amazonas', 'ambiente', 'ameaca', 'america',\n       'americanas', 'amplia', 'analise', 'analistas', 'antecipa',\n       'anulacao', 'anulou', 'anuncia', 'anuncio', 'apenas', 'apesar',\n       'apetite', 'apoiado', 'aponta', 'aposta', 'apostando', 'apostar',\n       'apostas', 'apreensao', 'aprova', 'aprovacao', 'aprovam',\n       'aprovar', 'aproveitar', 'aproxima', 'aproximar', 'aquisicao',\n       'aquisicoes', 'arbitragem', 'arezzo', 'argentina', 'arrendamento',\n       'arrendar', 'assembleia', 'assina', 'assinam', 'assume', 'assumir',\n       'assumira', 'ataque', 'atencao', 'atende', 'atender', 'atendera',\n       'atento', 'atenua', 'atinge', 'ativos', 'audiencia', 'aumenta',\n       'aumentam', 'aumentar', 'aumento', 'aumentos', 'autonomia',\n       'autoriza', 'auxilio', 'avalia', 'avanca', 'avancam', 'avanco',\n       'aversao', 'aviacao', 'baixar', 'baixas', 'balanco', 'balancos',\n       'bancos', 'barata', 'barato', 'barbosa', 'barril', 'barris',\n       'bateria', 'bidi11', 'bilhao', 'bilhoes', 'bilionaria',\n       'biodiesel', 'blocos', 'bloqueiam', 'bolivia', 'bolsas',\n       'bolsonaro', 'botijao', 'bovespa', 'bpac11', 'bradesco', 'branco',\n       'brasil', 'brasileira', 'brasileiras', 'brasileiros', 'brasilia',\n       'braskem', 'buzios', 'caindo', 'camara', 'caminha', 'caminho',\n       'caminhoneiros', 'campos', 'carrefour', 'carteira', 'carteiras',\n       'castello', 'cautela', 'cenario', 'centromenos', 'cessao',\n       'chamam', 'chances', 'chegou', 'claudio', 'clientes', 'climatica',\n       'cobram', 'cofins', 'coisas', 'colombia', 'comando', 'combate',\n       'combustiveis', 'combustivel', 'comeca', 'comeco', 'comissao',\n       'comite', 'commodities', 'companhia', 'compass', 'compensacoes',\n       'compensar', 'competitividade', 'compra', 'comprar', 'compras',\n       'compre', 'compromissadas', 'concessao', 'concessoes', 'conclui',\n       'concluir', 'concorrentes', 'condenacoes', 'confira', 'confirma',\n       'conforme', 'conformidade', 'congresso', 'conseguira',\n       'conselheiros', 'conselho', 'consorcio', 'construcao', 'consumo',\n       'conter', 'contra', 'contramao', 'contrata', 'contratacao',\n       'contrato', 'contratos', 'controle', 'convoca', 'copagaz',\n       'coparticipacao', 'corporativa', 'corporativas', 'corporativo',\n       'corretoras', 'cortar', 'cotado', 'covidmenos', 'cozinha',\n       'credit', 'credito', 'cresce', 'crescem', 'crescer', 'crescimento',\n       'critica', 'cumprira', 'custar', 'cyrela', 'daniel', 'debate',\n       'decepcao', 'decisao', 'decisoes', 'declaracoes', 'declinio',\n       'defasada', 'defasado', 'defasagem', 'defende', 'define',\n       'definir', 'demanda', 'demite', 'denuncia', 'deputados',\n       'derivados', 'derrocada', 'derruba', 'derrubam', 'desaba',\n       'desabam', 'desativar', 'desclassifica', 'descola', 'desconforto',\n       'descontos', 'descubra', 'desempenho', 'desinvestimentos',\n       'desiste', 'desmotiva', 'despenca', 'destacam', 'destaque',\n       'destaques', 'destituicao', 'destoa', 'devera', 'dezembro',\n       'diante', 'diesel', 'dificil', 'dinheiro', 'direito', 'diretor',\n       'discreta', 'discurso', 'discute', 'discutir', 'dispara',\n       'disparada', 'disparam', 'disparar', 'disputa', 'distribuicao',\n       'distribuidora', 'distribuidoras', 'distribuir', 'divida',\n       'dividas', 'dividendos', 'divulga', 'domestica', 'domesticas',\n       'domestico', 'duvida', 'duvidas', 'economia', 'economica',\n       'ecorodovias', 'edital', 'efeito', 'efeitos', 'eficiente',\n       'eleger', 'eleicao', 'eleicoes', 'eletricas', 'eletrobras',\n       'elevam', 'elevar', 'embraer', 'emenos', 'emergencial', 'emissao',\n       'emissoes', 'empresa', 'empresas', 'enauta', 'encerra', 'encerrar',\n       'encontra', 'encosta', 'energia', 'energy', 'enfrenta',\n       'enfrentar', 'engata', 'enquanto', 'ensaia', 'entenda', 'entrada',\n       'entrar', 'entrou', 'equinor', 'escala', 'escolhe', 'escritorio',\n       'espaco', 'especialistas', 'espera', 'esperado', 'estabilidade',\n       'estabilizacao', 'estados', 'estatais', 'estatal', 'estavel',\n       'estima', 'estimativa', 'estimulo', 'estimulos', 'estoques',\n       'estradas', 'estrategia', 'estrategico', 'estreia', 'estuda',\n       'esvazia', 'etanol', 'europa', 'exagerada', 'excelerate',\n       'executivo', 'executivos', 'exmenos', 'expectativa',\n       'expectativas', 'exportacao', 'exportacoes', 'exportadoras',\n       'exterior', 'externa', 'externo', 'fabrica', 'fabricas', 'fachin',\n       'familias', 'fantasma', 'favoravel', 'favoritas', 'fechamento',\n       'fechar', 'federal', 'feriado', 'feriados', 'ferreira',\n       'fertilizantes', 'fevereiro', 'financeira', 'financiar', 'fiscais',\n       'fiscal', 'flerta', 'flertar', 'fluxys', 'folego', 'follow',\n       'fontes', 'fornecimento', 'fraqueza', 'fundos', 'fusoes', 'futura',\n       'futuro', 'ganhar', 'ganhos', 'garante', 'gasoduto', 'gasodutos',\n       'gasolina', 'gaspetro', 'gastos', 'general', 'gerdau', 'gerencia',\n       'gerente', 'gestao', 'globais', 'global', 'goldman', 'governanca',\n       'governo', 'grafica', 'guedes', 'guiado', 'hapvida', 'havera',\n       'hering', 'hesita', 'hesitacao', 'hidratado', 'hidrica',\n       'historia', 'historica', 'historico', 'holanda', 'holofotes',\n       'hypera', 'ibovespa', 'impacto', 'importacao', 'importar',\n       'impostos', 'impulsiona', 'impulsionado', 'impulso', 'incerteza',\n       'incertezas', 'inclui', 'indefinicao', 'indica', 'indicacao',\n       'indicacoes', 'indicada', 'indicadas', 'indicam', 'indice',\n       'inedito', 'inflacao', 'influencia', 'influenciado', 'informa',\n       'informacao', 'ingerencia', 'inicia', 'inicio', 'insider',\n       'instabilidade', 'instavel', 'institucional', 'instituicoes',\n       'interferencia', 'internacionais', 'internacional', 'interno',\n       'intervencao', 'inverte', 'investidor', 'investidores',\n       'investigacao', 'investigar', 'investimentos', 'investir',\n       'investira', 'ipcamenos', 'ipiranga', 'irregularidades', 'itausa',\n       'janeiro', 'jornal', 'jpmorgan', 'julgamento', 'justica', 'karoon',\n       'klabin', 'lavagem', 'leilao', 'leiloes', 'leniencia', 'lentidao',\n       'levantamento', 'levantar', 'libera', 'liberal', 'licitacao',\n       'lidera', 'liderada', 'lideram', 'liderando', 'ligadas', 'limitam',\n       'linhas', 'liquidez', 'liquigas', 'locais', 'localiza', 'londres',\n       'lucrar', 'lucros', 'magalu', 'magazine', 'maiores', 'manifesta',\n       'manifestacoes', 'mantem', 'manter', 'manutencao', 'maquina',\n       'marcada', 'marfrig', 'marlim', 'martins', 'maxima', 'maximas',\n       'medidas', 'melhor', 'melhora', 'melhores', 'meliuz', 'mensal',\n       'mercado', 'mercados', 'metade', 'milhao', 'milhoes', 'mineracao',\n       'minerio', 'minerva', 'minima', 'minimas', 'minimo', 'ministerio',\n       'ministro', 'minoritarios', 'mistura', 'momento', 'monopolio',\n       'mostra', 'motivo', 'motivos', 'mourao', 'movida', 'movimento',\n       'mubadala', 'mudanca', 'mudancas', 'mundial', 'nacional',\n       'naomenos', 'natura', 'natural', 'necton', 'negativa', 'negativo',\n       'negociacao', 'negociacoes', 'negocios', 'neoenergia',\n       'neutralidade', 'ninguem', 'nitrogenados', 'niveis', 'noticiario',\n       'noticias', 'notredame', 'novamente', 'novembro', 'novidades',\n       'numeros', 'oceanpact', 'odebrecht', 'oferta', 'ofertas', 'office',\n       'offshore', 'ofusca', 'omicron', 'onerosa', 'opcoes', 'operacao',\n       'operador', 'operar', 'orcamento', 'oscila', 'otimismo', 'outras',\n       'outubro', 'pacheco', 'pacote', 'pactual', 'pagamento', 'pagarao',\n       'pandemia', 'papeis', 'parada', 'parana', 'parceria', 'parcial',\n       'parecer', 'participacao', 'partilha', 'partir', 'patamar',\n       'patinho', 'pedido', 'percepcao', 'perdas', 'perfura', 'permanece',\n       'permanente', 'permite', 'perspectiva', 'pessimismo', 'petrobras',\n       'petroleiras', 'petroleiros', 'petroleo', 'petroleum', 'petromais',\n       'petroreconcavo', 'petrorio', 'petros', 'piorar', 'planeja',\n       'plataforma', 'plataformas', 'plenario', 'pmenos', 'podera',\n       'policia', 'politica', 'politico', 'politicomenos', 'politicos',\n       'pontos', 'portfolio', 'positiva', 'positivo', 'positivos',\n       'possivel', 'postos', 'potiguar', 'powell', 'precatorios',\n       'precisa', 'precomenos', 'precos', 'preferidas', 'pregao',\n       'premenos', 'preocupa', 'preocupacoes', 'preocupam', 'prepara',\n       'preparam', 'presidente', 'pressao', 'pressiona', 'pressionado',\n       'pressoes', 'prevalece', 'previa', 'primeira', 'principais',\n       'privatizacao', 'privatizar', 'privilegiada', 'problema',\n       'processamento', 'processo', 'producao', 'profundas', 'profundo',\n       'programa', 'programada', 'projecoes', 'projeto', 'promessa',\n       'promete', 'propina', 'proposta', 'propostas', 'prorroga',\n       'proteger', 'protesto', 'protestos', 'proxima', 'proximo',\n       'proximos', 'publica', 'puxada', 'puxado', 'qualicorp', 'quarta',\n       'quatro', 'quebra', 'quedas', 'questiona', 'quinta', 'raizen',\n       'randon', 'ranking', 'reafirma', 'reajusta', 'reajuste',\n       'reajustes', 'realiza', 'realizacao', 'rebalanceamento', 'recebe',\n       'receio', 'receios', 'receita', 'recomenda', 'recomendacao',\n       'recomendacoes', 'recomendada', 'recomendadas', 'recompra',\n       'recorde', 'recordes', 'recupera', 'recuperacao', 'recuperando',\n       'recursos', 'reducao', 'reduzido', 'reduzir', 'reduzira',\n       'referencia', 'refinaria', 'refinarias', 'refino', 'reforca',\n       'reforma', 'regaseificacao', 'regiao', 'registra', 'relator',\n       'remove', 'remuneracao', 'render', 'rendeu', 'renegociam',\n       'renner', 'renova', 'renovar', 'renovavel', 'repasse', 'reserve',\n       'resiste', 'respaldo', 'respeito', 'respiro', 'resposta',\n       'restricoes', 'resultado', 'resultados', 'retoma', 'retomada',\n       'retorna', 'retorno', 'retornos', 'reverte', 'reverter', 'riscos',\n       'robusta', 'robusto', 'rodada', 'royalties', 'sabesp', 'saltam',\n       'samsung', 'sanb11', 'santander', 'santos', 'satisfaz', 'seguida',\n       'seguidas', 'seguido', 'seguir', 'segunda', 'segundo', 'segura',\n       'seguridade', 'selecao', 'seleciona', 'semana', 'semanais',\n       'semanal', 'semanas', 'semestre', 'senado', 'senador', 'senadores',\n       'sentenca', 'sequencia', 'sergio', 'sergipe', 'servico',\n       'servicos', 'sessao', 'setembro', 'setores', 'siderurgia',\n       'siderurgicas', 'simples', 'sinais', 'sinaliza', 'sindicatos',\n       'sinqia', 'sismica', 'sistema', 'smartfit', 'smenos', 'smiles',\n       'social', 'sociedade', 'solucao', 'startups', 'street', 'subindo',\n       'subira', 'subsidiar', 'subsidiaria', 'subsidiarias', 'substitui',\n       'sucumbe', 'sugerem', 'sugestoes', 'suisse', 'supera', 'superar',\n       'suspende', 'suspensao', 'sustenta', 'suzano', 'teaser',\n       'tecnologia', 'telecomunicacoes', 'tensao', 'terceiro', 'termica',\n       'termicas', 'terminal', 'terreno', 'terrestres', 'ticket',\n       'tirados', 'titulo', 'titulos', 'totalenergies', 'trabalhista',\n       'trabalho', 'trafigura', 'transporte', 'trazer', 'tributaria',\n       'trimestre', 'trocas', 'turbulencia', 'turbulencias', 'turquia',\n       'ultima', 'ultimo', 'ultrapar', 'ultrapassa', 'unidade',\n       'unidades', 'unidas', 'unigel', 'usiminas', 'usinas', 'vacina',\n       'vacinas', 'valecard', 'valemenos', 'valores', 'varejistas',\n       'varejo', 'variante', 'vazamento', 'vencimento', 'vencimentos',\n       'vendas', 'vender', 'vermelho', 'vespera', 'vinculante',\n       'vinculantes', 'volatil', 'volatilidade', 'voltar', 'volume',\n       'warren'], dtype=object)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_vec.get_feature_names_out()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T15:00:50.337770100Z",
     "start_time": "2023-05-23T15:00:50.305788Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Grid Params"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### KNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_params = {\n",
    "    # 'n_neighbors': [11, 21, 40, 60, 80, 100],\n",
    "    'n_neighbors': [15 ,17 ,19, 21, 23, 25, 27],\n",
    "    'metric': ['cosine'],\n",
    "    'weights': ['distance']\n",
    "    # 'weights': ['uniform', 'distance'],\n",
    "    # 'metric': ['cosine']\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T15:00:50.707664500Z",
     "start_time": "2023-05-23T15:00:50.340768200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SVM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_params = {\n",
    "    # 'C': [1,10, 50, 100],\n",
    "    'C': [1,5,10],\n",
    "    # 'C': [1,5,10],\n",
    "    # 'kernel': ['rbf']\n",
    "    # 'kernel' : ['rbf'],\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T15:00:50.708666600Z",
     "start_time": "2023-05-23T15:00:50.695672300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Naive Bayes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb_params = {\n",
    "    'alpha': [0.1, 1, 10],\n",
    "    'fit_prior': [True, False]\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T15:00:50.727673300Z",
     "start_time": "2023-05-23T15:00:50.697671500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_params = {\n",
    "    'penalty': ['l1','l2', None],\n",
    "    'C': [0.1, 1, 10],\n",
    "    'solver': ['liblinear','sag', 'saga']\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T15:00:50.755656500Z",
     "start_time": "2023-05-23T15:00:50.730671700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tuning and Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "\n",
    "split_index = [-1] * len(train) + [0] * len(val)\n",
    "\n",
    "X = pd.concat([train, val], axis=0, ignore_index=True)\n",
    "\n",
    "y = np.concatenate((y_train, y_val), axis=0)\n",
    "pds = PredefinedSplit(test_fold=split_index)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T15:00:50.767649300Z",
     "start_time": "2023-05-23T15:00:50.744663300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Count Vectorizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "      abaixo  abertura  abicom  absurdo  aceita  acelera  acelerar  \\\n0          0         0       0        0       0        0         0   \n1          0         0       0        0       0        0         0   \n2          0         0       0        0       0        0         0   \n3          0         0       0        0       0        0         0   \n4          0         0       0        0       0        0         0   \n...      ...       ...     ...      ...     ...      ...       ...   \n1881       0         0       0        0       0        0         0   \n1882       0         0       0        0       0        0         0   \n1883       0         0       0        0       0        0         0   \n1884       0         0       0        0       0        0         0   \n1885       0         0       0        0       0        0         0   \n\n      acionistas  acompanha  acordo  ...  vender  vermelho  vespera  \\\n0              0          0       0  ...       0         0        0   \n1              0          0       0  ...       0         0        0   \n2              0          0       0  ...       0         0        0   \n3              0          0       0  ...       0         0        0   \n4              0          0       0  ...       0         0        0   \n...          ...        ...     ...  ...     ...       ...      ...   \n1881           0          0       0  ...       0         0        0   \n1882           0          0       0  ...       0         0        0   \n1883           0          0       0  ...       0         0        0   \n1884           0          0       0  ...       0         0        0   \n1885           0          0       0  ...       0         0        0   \n\n      vinculante  vinculantes  volatil  volatilidade  voltar  volume  warren  \n0              0            0        0             0       0       0       0  \n1              0            0        0             0       0       0       0  \n2              0            0        0             0       0       0       0  \n3              0            0        0             0       0       0       0  \n4              0            0        0             0       0       0       0  \n...          ...          ...      ...           ...     ...     ...     ...  \n1881           0            0        0             0       0       0       0  \n1882           0            0        0             0       0       0       0  \n1883           0            0        0             0       0       0       0  \n1884           0            0        0             0       0       0       0  \n1885           0            0        0             0       0       1       0  \n\n[1886 rows x 912 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>abaixo</th>\n      <th>abertura</th>\n      <th>abicom</th>\n      <th>absurdo</th>\n      <th>aceita</th>\n      <th>acelera</th>\n      <th>acelerar</th>\n      <th>acionistas</th>\n      <th>acompanha</th>\n      <th>acordo</th>\n      <th>...</th>\n      <th>vender</th>\n      <th>vermelho</th>\n      <th>vespera</th>\n      <th>vinculante</th>\n      <th>vinculantes</th>\n      <th>volatil</th>\n      <th>volatilidade</th>\n      <th>voltar</th>\n      <th>volume</th>\n      <th>warren</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1881</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1882</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1883</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1884</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1885</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1886 rows × 912 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cv = cv_vec.transform(X['title']).toarray()\n",
    "pd.DataFrame(X_cv, columns=cv_vec.get_feature_names_out())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T15:00:50.820618600Z",
     "start_time": "2023-05-23T15:00:50.761653Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T15:00:50.836621800Z",
     "start_time": "2023-05-23T15:00:50.821619Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV results for KNeighborsClassifier\n",
      "Best Score of train set: 0.5657516174757553\n",
      "Best estimator: KNeighborsClassifier(metric='cosine', n_neighbors=27, weights='distance')\n",
      "Best parameter set: {'metric': 'cosine', 'n_neighbors': 27, 'weights': 'distance'}\n",
      "Best CV results for SVC\n",
      "Best Score of train set: 0.5805959047338358\n",
      "Best estimator: SVC(C=1)\n",
      "Best parameter set: {'C': 1}\n",
      "Best CV results for MultinomialNB\n",
      "Best Score of train set: 0.5774128808611567\n",
      "Best estimator: MultinomialNB(alpha=10)\n",
      "Best parameter set: {'alpha': 10, 'fit_prior': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV results for LogisticRegression\n",
      "Best Score of train set: 0.5784738888187164\n",
      "Best estimator: LogisticRegression(C=0.1, solver='liblinear')\n",
      "Best parameter set: {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "30 fits failed out of a total of 135.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1216, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\svm\\_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\svm\\_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='None' and loss='logistic_regression' is not supported, Parameters: penalty=None, loss='logistic_regression', dual=False\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.57794338        nan 0.57794338 0.57847389 0.57741288 0.57741288\n",
      "        nan 0.45600185 0.45546854 0.55195711        nan 0.54877409\n",
      " 0.54401359 0.5307552  0.5307552         nan 0.45122732 0.45546854\n",
      " 0.47613715        nan 0.4676561  0.49257856 0.47720377 0.47826618\n",
      "        nan 0.45228832 0.45547416]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "             model_name  best_score  \\\n0  KNeighborsClassifier    0.565752   \n1                   SVC    0.580596   \n2         MultinomialNB    0.577413   \n3    LogisticRegression    0.578474   \n\n                                      best_estimator  \\\n0  KNeighborsClassifier(metric='cosine', n_neighb...   \n1                                           SVC(C=1)   \n2                            MultinomialNB(alpha=10)   \n3      LogisticRegression(C=0.1, solver='liblinear')   \n\n                                         best_params  \n0  {'metric': 'cosine', 'n_neighbors': 27, 'weigh...  \n1                                           {'C': 1}  \n2                   {'alpha': 10, 'fit_prior': True}  \n3  {'C': 0.1, 'penalty': 'l2', 'solver': 'libline...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model_name</th>\n      <th>best_score</th>\n      <th>best_estimator</th>\n      <th>best_params</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>KNeighborsClassifier</td>\n      <td>0.565752</td>\n      <td>KNeighborsClassifier(metric='cosine', n_neighb...</td>\n      <td>{'metric': 'cosine', 'n_neighbors': 27, 'weigh...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>SVC</td>\n      <td>0.580596</td>\n      <td>SVC(C=1)</td>\n      <td>{'C': 1}</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>MultinomialNB</td>\n      <td>0.577413</td>\n      <td>MultinomialNB(alpha=10)</td>\n      <td>{'alpha': 10, 'fit_prior': True}</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>LogisticRegression</td>\n      <td>0.578474</td>\n      <td>LogisticRegression(C=0.1, solver='liblinear')</td>\n      <td>{'C': 0.1, 'penalty': 'l2', 'solver': 'libline...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# from hypopt import GridSearch\n",
    "\n",
    "model_params = ([KNeighborsClassifier(), SVC(), MultinomialNB(), LogisticRegression()],\n",
    "                [knn_params, svm_params, nb_params, lr_params])\n",
    "\n",
    "list_best_models_params = []\n",
    "for model, params in zip(model_params[0], model_params[1]):\n",
    "    gs = GridSearchCV(model,\n",
    "                      param_grid=params,\n",
    "                      )\n",
    "\n",
    "    gs.fit(X_cv, y)\n",
    "    print(f\"Best CV results for {model.__class__.__name__}\")\n",
    "    print(\"Best Score of train set: \" + str(gs.best_score_))\n",
    "    print(\"Best estimator: \" + str(gs.best_estimator_))\n",
    "    print(\"Best parameter set: \" + str(gs.best_params_))\n",
    "\n",
    "    store_best_model_configs = {\n",
    "        'model_name': model.__class__.__name__,\n",
    "        'best_score': gs.best_score_,\n",
    "        'best_estimator': gs.best_estimator_,\n",
    "        'best_params': gs.best_params_\n",
    "    }\n",
    "\n",
    "    list_best_models_params.append(store_best_model_configs)\n",
    "\n",
    "df_best_models_params = pd.DataFrame(list_best_models_params)\n",
    "df_best_models_params.to_csv('../../assets/traditional_assets/best_models_params_cv.csv', index=False)\n",
    "\n",
    "df_best_models_params\n",
    "# cv_best_model = gs.best_estimator_\n",
    "# print(\"Test Score: \" + str(gs.score(X_val_cv, y_val)))\n",
    "# print(\"----------------------------------------------------\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T15:04:42.285254400Z",
     "start_time": "2023-05-23T15:00:50.837621800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "LogisticRegression(C=0.1, solver='liblinear')",
      "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.1, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.1, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cv_best_model = gs.best_estimator_\n",
    "cv_best_model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T15:04:42.300245500Z",
     "start_time": "2023-05-23T15:04:42.286254Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T15:04:42.344219300Z",
     "start_time": "2023-05-23T15:04:42.301245600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### TF-IDF"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "      abaixo  abertura  abicom  absurdo  aceita  acelera  acelerar  \\\n0        0.0       0.0     0.0      0.0     0.0      0.0       0.0   \n1        0.0       0.0     0.0      0.0     0.0      0.0       0.0   \n2        0.0       0.0     0.0      0.0     0.0      0.0       0.0   \n3        0.0       0.0     0.0      0.0     0.0      0.0       0.0   \n4        0.0       0.0     0.0      0.0     0.0      0.0       0.0   \n...      ...       ...     ...      ...     ...      ...       ...   \n1881     0.0       0.0     0.0      0.0     0.0      0.0       0.0   \n1882     0.0       0.0     0.0      0.0     0.0      0.0       0.0   \n1883     0.0       0.0     0.0      0.0     0.0      0.0       0.0   \n1884     0.0       0.0     0.0      0.0     0.0      0.0       0.0   \n1885     0.0       0.0     0.0      0.0     0.0      0.0       0.0   \n\n      acionistas  acompanha  acordo  ...  vender  vermelho  vespera  \\\n0            0.0        0.0     0.0  ...     0.0       0.0      0.0   \n1            0.0        0.0     0.0  ...     0.0       0.0      0.0   \n2            0.0        0.0     0.0  ...     0.0       0.0      0.0   \n3            0.0        0.0     0.0  ...     0.0       0.0      0.0   \n4            0.0        0.0     0.0  ...     0.0       0.0      0.0   \n...          ...        ...     ...  ...     ...       ...      ...   \n1881         0.0        0.0     0.0  ...     0.0       0.0      0.0   \n1882         0.0        0.0     0.0  ...     0.0       0.0      0.0   \n1883         0.0        0.0     0.0  ...     0.0       0.0      0.0   \n1884         0.0        0.0     0.0  ...     0.0       0.0      0.0   \n1885         0.0        0.0     0.0  ...     0.0       0.0      0.0   \n\n      vinculante  vinculantes  volatil  volatilidade  voltar    volume  warren  \n0            0.0          0.0      0.0           0.0     0.0  0.000000     0.0  \n1            0.0          0.0      0.0           0.0     0.0  0.000000     0.0  \n2            0.0          0.0      0.0           0.0     0.0  0.000000     0.0  \n3            0.0          0.0      0.0           0.0     0.0  0.000000     0.0  \n4            0.0          0.0      0.0           0.0     0.0  0.000000     0.0  \n...          ...          ...      ...           ...     ...       ...     ...  \n1881         0.0          0.0      0.0           0.0     0.0  0.000000     0.0  \n1882         0.0          0.0      0.0           0.0     0.0  0.000000     0.0  \n1883         0.0          0.0      0.0           0.0     0.0  0.000000     0.0  \n1884         0.0          0.0      0.0           0.0     0.0  0.000000     0.0  \n1885         0.0          0.0      0.0           0.0     0.0  0.656334     0.0  \n\n[1886 rows x 912 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>abaixo</th>\n      <th>abertura</th>\n      <th>abicom</th>\n      <th>absurdo</th>\n      <th>aceita</th>\n      <th>acelera</th>\n      <th>acelerar</th>\n      <th>acionistas</th>\n      <th>acompanha</th>\n      <th>acordo</th>\n      <th>...</th>\n      <th>vender</th>\n      <th>vermelho</th>\n      <th>vespera</th>\n      <th>vinculante</th>\n      <th>vinculantes</th>\n      <th>volatil</th>\n      <th>volatilidade</th>\n      <th>voltar</th>\n      <th>volume</th>\n      <th>warren</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1881</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1882</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1883</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1884</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1885</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.656334</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1886 rows × 912 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train_tfidf = tfidf_vec.transform(X_train['title'])\n",
    "# X_val_tfidf = tfidf_vec.transform(X_val['title'])\n",
    "# X_train_tfidf\n",
    "X_tfidf = tfidf_vec.transform(X['title']).toarray()\n",
    "pd.DataFrame(X_tfidf, columns=tfidf_vec.get_feature_names_out())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T15:04:42.477143500Z",
     "start_time": "2023-05-23T15:04:42.317237Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best TF-IDF results for KNeighborsClassifier\n",
      "Best Score on train set: 0.5684041373696547\n",
      "Best estimator: KNeighborsClassifier(metric='cosine', n_neighbors=27, weights='distance')\n",
      "Best parameter set: {'metric': 'cosine', 'n_neighbors': 27, 'weights': 'distance'}\n",
      "\n",
      "Best TF-IDF results for SVC\n",
      "Best Score on train set: 0.5779433848399366\n",
      "Best estimator: SVC(C=1)\n",
      "Best parameter set: {'C': 1}\n",
      "\n",
      "Best TF-IDF results for MultinomialNB\n",
      "Best Score on train set: 0.5779433848399366\n",
      "Best estimator: MultinomialNB(alpha=10)\n",
      "Best parameter set: {'alpha': 10, 'fit_prior': True}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best TF-IDF results for LogisticRegression\n",
      "Best Score on train set: 0.5779433848399366\n",
      "Best estimator: LogisticRegression(C=0.1, penalty='l1', solver='liblinear')\n",
      "Best parameter set: {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "30 fits failed out of a total of 135.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1216, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\svm\\_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\svm\\_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='None' and loss='logistic_regression' is not supported, Parameters: penalty=None, loss='logistic_regression', dual=False\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Guilherme\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.57794338        nan 0.57794338 0.57794338 0.57794338 0.57794338\n",
      "        nan 0.4517494  0.45970415 0.57529227        nan 0.57423126\n",
      " 0.56945813 0.56998863 0.56998863        nan 0.45493804 0.46129847\n",
      " 0.4840933         nan 0.48302668 0.50211921 0.48515571 0.4994723\n",
      "        nan 0.45599624 0.45811404]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "             model_name  best_score  \\\n0  KNeighborsClassifier    0.568404   \n1                   SVC    0.577943   \n2         MultinomialNB    0.577943   \n3    LogisticRegression    0.577943   \n\n                                      best_estimator  \\\n0  KNeighborsClassifier(metric='cosine', n_neighb...   \n1                                           SVC(C=1)   \n2                            MultinomialNB(alpha=10)   \n3  LogisticRegression(C=0.1, penalty='l1', solver...   \n\n                                         best_params  \n0  {'metric': 'cosine', 'n_neighbors': 27, 'weigh...  \n1                                           {'C': 1}  \n2                   {'alpha': 10, 'fit_prior': True}  \n3  {'C': 0.1, 'penalty': 'l1', 'solver': 'libline...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model_name</th>\n      <th>best_score</th>\n      <th>best_estimator</th>\n      <th>best_params</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>KNeighborsClassifier</td>\n      <td>0.568404</td>\n      <td>KNeighborsClassifier(metric='cosine', n_neighb...</td>\n      <td>{'metric': 'cosine', 'n_neighbors': 27, 'weigh...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>SVC</td>\n      <td>0.577943</td>\n      <td>SVC(C=1)</td>\n      <td>{'C': 1}</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>MultinomialNB</td>\n      <td>0.577943</td>\n      <td>MultinomialNB(alpha=10)</td>\n      <td>{'alpha': 10, 'fit_prior': True}</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>LogisticRegression</td>\n      <td>0.577943</td>\n      <td>LogisticRegression(C=0.1, penalty='l1', solver...</td>\n      <td>{'C': 0.1, 'penalty': 'l1', 'solver': 'libline...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model_params = ([KNeighborsClassifier(), SVC(), MultinomialNB(), LogisticRegression()],\n",
    "                [knn_params, svm_params, nb_params, lr_params])\n",
    "\n",
    "list_best_models_params = []\n",
    "for model, params in zip(model_params[0], model_params[1]):\n",
    "    gs = GridSearchCV(model,\n",
    "                      param_grid=params,\n",
    "                      )\n",
    "    gs.fit(X_tfidf, y)\n",
    "    print(f\"Best TF-IDF results for {model.__class__.__name__}\")\n",
    "    print(\"Best Score on train set: \" + str(gs.best_score_))\n",
    "    print(\"Best estimator: \" + str(gs.best_estimator_))\n",
    "    print(\"Best parameter set: \" + str(gs.best_params_) + \"\\n\")\n",
    "    store_best_model_configs = {\n",
    "        'model_name': model.__class__.__name__,\n",
    "        'best_score': gs.best_score_,\n",
    "        'best_estimator': gs.best_estimator_,\n",
    "        'best_params': gs.best_params_\n",
    "    }\n",
    "\n",
    "    list_best_models_params.append(store_best_model_configs)\n",
    "\n",
    "df_best_models_params = pd.DataFrame(list_best_models_params)\n",
    "df_best_models_params.to_csv('../../assets/traditional_assets/best_models_params_tfidf.csv', index=False)\n",
    "df_best_models_params\n",
    "\n",
    "\n",
    "# decide_best_model =\n",
    "# print(\"Test Score: \" + str(gs.score(X_val, y_val)))\n",
    "# print(\"----------------------------------------------------\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T15:08:06.492287800Z",
     "start_time": "2023-05-23T15:04:42.419177400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T15:08:06.535261900Z",
     "start_time": "2023-05-23T15:08:06.492287800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "LogisticRegression(C=0.1, penalty='l1', solver='liblinear')",
      "text/html": "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.1, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.1, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_best_model = gs.best_estimator_\n",
    "tfidf_best_model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T15:08:06.582234400Z",
     "start_time": "2023-05-23T15:08:06.508278400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Outputs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "with open('../../assets/traditional_assets/cv_set.pkl', 'wb') as fout:\n",
    "    pickle.dump((cv_vec, cv_best_model), fout)\n",
    "\n",
    "with open('../../assets/traditional_assets/tfidf_set.pkl', 'wb') as fout:\n",
    "    pickle.dump((tfidf_vec, cv_best_model), fout)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T15:08:06.600224900Z",
     "start_time": "2023-05-23T15:08:06.524268900Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
